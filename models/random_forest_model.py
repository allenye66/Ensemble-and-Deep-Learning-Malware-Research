import pandas as pd
import numpy as np
import sklearn.metrics as metrics
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels
import seaborn as sns
import pickle
from sklearn.metrics import balanced_accuracy_score

df = pd.read_csv('/Users/allen/Desktop/Malware-Research/csv/all_data.csv')

print(df.Family.unique())



df.Family = df.Family.replace({"ADLOAD": 0})
df.Family = df.Family.replace({"AGENT": 1})
df.Family = df.Family.replace({"ALLAPLE_A": 2})
df.Family = df.Family.replace({"BHO": 3})
df.Family = df.Family.replace({"BIFROSE": 4})
df.Family = df.Family.replace({"CEEINJECT": 5})
df.Family = df.Family.replace({"CYCBOT_G": 6})
df.Family = df.Family.replace({"FAKEREAN": 7})
df.Family = df.Family.replace({"HOTBAR": 8})
df.Family = df.Family.replace({"INJECTOR": 9})

df.Family = df.Family.replace({"ONLINEGAMES": 10})
df.Family = df.Family.replace({"RENOS": 11})
df.Family = df.Family.replace({"RIMECUD_A": 12})
df.Family = df.Family.replace({"SMALL": 13})
df.Family = df.Family.replace({"TOGA_RFN": 14})
df.Family = df.Family.replace({"VB": 15})
df.Family = df.Family.replace({"VBINJECT": 16})
df.Family = df.Family.replace({"VOBFUS": 17})

df.Family = df.Family.replace({"VUNDO": 18})
df.Family = df.Family.replace({"WINWEBSEC": 29})
df.Family = df.Family.replace({"ZBOT": 20})



df = df.loc[:, df.columns != 'Total Opcodes']
df = df.loc[:, df.columns != 'File Name']


for i in range(31):
    df = df.drop(df.columns[1], axis=1)



opcode_sequence = (df.drop(df.columns[0], axis=1))
opcode_sequence = np.asarray(opcode_sequence)


labels = np.asarray(df[['Family']].copy())


from sklearn.preprocessing import LabelEncoder
#le = LabelEncoder()
#labels = le.fit_transform(labels)


X_train, X_test, y_train, y_test = train_test_split(opcode_sequence, labels, test_size=0.1, random_state=42)

print(np.unique(y_train))

#{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50}
#{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}
#{'n_estimators': 500, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 30}

#{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 40}        
#rf = RandomForestClassifier(n_estimators = 300, min_samples_split = 2, min_samples_leaf =2, max_features = 'sqrt', max_depth= 30)

#rf = RandomForestClassifier(n_estimators = 500, min_samples_split = 15, min_samples_leaf = 1, max_features = 'auto', max_depth= 30)
rf = RandomForestClassifier(n_estimators = 200, min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto', max_depth= 40)

#rf = RandomForestClassifier(max_depth=50, random_state=0)
rf.fit(X_train, y_train)

rf_preds = rf.predict(X_test)
rf_accuracy =  metrics.accuracy_score(y_test, rf_preds)
print("random forest:", rf_accuracy)

print("balanced_accuracy_score:", metrics.balanced_accuracy_score(y_test, rf_preds))

#pickle.dump(rf, open('random_forest_model.sav', 'wb'))


'''
#n_estimators = [500, 800, 1500, 2500, 5000]
n_estimators = [100]
min_samples_split = [2, 5, 10, 15, 20]
min_samples_leaf = [1, 2, 5, 10, 15]
max_features = ['auto', 'sqrt','log2']
#max_depth = [10, 20, 30, 40, 50, 60, 70, 80]
max_depth = [50, 60, 70]
max_depth.append(None)





##RESUTS
#n_estimators = 500, min_samples_split = 15, min_samples_leaf = 1, max_features = 'auto', max_depth= 30 
  #70%
#n_estimators = 150, min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto', max_depth= 50
  #~71




grid_param = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth':max_depth, 'min_samples_split':min_samples_split, 'min_samples_leaf': min_samples_leaf}

from sklearn.ensemble import RandomForestRegressor

from sklearn.model_selection import RandomizedSearchCV
RFR = RandomForestRegressor(random_state = 1)
RFR_random = RandomizedSearchCV(estimator = RFR, param_distributions = grid_param, n_iter = 500, cv =5, verbose = 2, random_state= 42, n_jobs = -1)
RFR_random.fit(X_train, y_train)
print(RFR_random.best_params_)



'''

'''
label_map = {"0":"ADLOAD","1":"BHO","2":"CEEINJECT","3":"LOLYDA_BF","4":"ONLINEGAMES","5":"RENOS","6":"STARTPAGE","7":"VBINJECT","8":"VOBFUS","9":"WINWEBSEC" }


#print(y_test)

def plot_confusion_matrix(y_true,y_predicted):
  cm = metrics.confusion_matrix(y_true, y_predicted)
  print ("Plotting the Confusion Matrix")
  labels = list(label_map.values())
  df_cm = pd.DataFrame(cm,index = labels,columns = labels)
  fig = plt.figure()
  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')
  plt.yticks([0.5,1.5,2.5,3.5,4.5, 5.5, 6.5, 7.5, 8.5, 9.5], labels,va='center')
  #plt.yticks([2,4,6,8,10,12, 14, 16, 18, 20], labels,va='center')

  plt.title('Confusion Matrix - TestData')
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
 
  plt.show()
  plt.close()

plot_confusion_matrix(y_test, rf_preds)

'''




'''

array = (confusion_matrix(y_test, rf_preds))

df_cm = pd.DataFrame(array, index = [i for i in "ABCDEFGHIJK"], columns = [i for i in "ABCDEFGHIJK"])
plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot=True)
'''

#plot_confusion_matrix( y_test2, rf_preds, classes=labels, title= 'Confusion matrix, without normalization')

#plot_confusion_matrix(labels_test, rf_preds,classes=class_names, normalize=True, title='Normalized confusion matrix')




#print(y_test2)
#print(rf_preds)
