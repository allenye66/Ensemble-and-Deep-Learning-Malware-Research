import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import model_selection
from sklearn.metrics import accuracy_score
from collections import Counter
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv1D
from keras.layers import Activation, MaxPooling1D, Dropout, Flatten, Reshape
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing

df = pd.read_csv('/Users/allen/Desktop/Malware-Research/csv/all_data.csv')
X = df.iloc[:, 34:]
Y = df.iloc[:, 1]

normalized_X = preprocessing.normalize(X)
X = normalized_X
X = np.expand_dims(X, 2)
print(X.shape)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
Y = le.fit_transform(Y)

def one_hot(n):
    arr = []
    for i in range(24):
        arr.append(0)
    arr[n] = 1
    return arr

labels = []
for i in range(len(Y)):
    #print(one_hot(Y[i]))
    labels.append(one_hot(Y[i]))
    
model = Sequential()

model.add(Conv1D(filters= 28, kernel_size=3, activation ='relu', input_shape= (1000, 1))) #takes in a total of 1000 sequential opcodes as features

model.add(Conv1D(filters= 16, kernel_size=3, activation ='relu'))


model.add(Dense(120))
#model.add(Activation('relu'))
model.add(Dense(90))
#model.add(Activation('relu'))

model.add(Flatten())

model.add(Dense(21)) #for 21 families
model.add(Activation('softmax'))

from keras.optimizers import SGD
opt = keras.optimizers.Adam(learning_rate=0.0001)

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


#model.summary()

from keras.optimizers import SGD
opt = SGD(lr=0.01)

model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

history = model.fit(X, Y, epochs = 30, validation_split = 0.1, batch_size = 64, shuffle=False)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

'''
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')

plt.legend(['loss', 'val loss' ], loc='upper left')
plt.show()
'''